import os
import markdown
from datetime import datetime
from src.llm_client import get_completion
from src.prompts import ANALYSIS_SYSTEM_PROMPT
from src.knowledge import get_concept_guide

class PsychAgent:
    """
    æ ¸å¿ƒ domainï¼šçµ¦å®š user_name / partner_name / context / chat_logs
    â†’ å›å‚³å®Œæ•´åˆ†æå ±å‘Šï¼ˆå­—ä¸²ï¼‰
    ä¸åŒ…å« I/Oã€ä¸åŒ…å« input()ã€ä¸åŒ…å« print()
    """

    def __init__(self, user_name="", partner_name="", context="", chat_logs=""):
        self.user_name = user_name
        self.partner_name = partner_name
        self.context = context
        self.chat_logs = chat_logs

    def build_prompt(self):
        """çµ„åˆå®Œæ•´ Prompt"""
        return ANALYSIS_SYSTEM_PROMPT.format(
            user_name=self.user_name,
            partner_name=self.partner_name,
            context=self.context,
            chat_logs=self.chat_logs
        )

    def analyze(self):
        """åŸ·è¡Œ LLMï¼Œåœ¨å‰é¢åŠ ä¸Šå¿ƒç†å­¸å°è®€"""
        prompt = self.build_prompt()
        messages = [{"role": "user", "content": prompt}]
        llm_output = get_completion(messages)

        if not llm_output:
            return "ï¼ˆåˆ†æå¤±æ•—ï¼šæ¨¡å‹ç„¡å›æ‡‰ï¼‰"

        return get_concept_guide() + "\n" + llm_output
class ChatAgent:
    def __init__(self):
        self.history = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æº«å’Œã€å°ˆæ¥­çš„æƒ…æ„Ÿè«®è©¢èŠå¤©æ©Ÿå™¨äººã€‚"},
            {"role": "assistant", "content": "æ‚¨å¥½ ğŸ˜Š è«‹å•ä»Šå¤©æƒ³èŠä»€éº¼å‘¢ï¼Ÿ"}
        ]
    def reply(self, user_message: str) -> str:
        self.history.append({"role": "user", "content": user_message})
        response = get_completion(self.history)

        if not response:
            response = "æŠ±æ­‰ï¼Œæˆ‘å‰›å‰›æœ‰é»åˆ†å¿ƒäº†ï¼Œå¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ"

        self.history.append({"role": "assistant", "content": response})
        return response